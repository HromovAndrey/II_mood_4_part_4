{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/andrey36912/notebook6ff449cabb?scriptVersionId=191680720\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-08T17:20:27.174804Z","iopub.execute_input":"2024-08-08T17:20:27.175557Z","iopub.status.idle":"2024-08-08T17:20:27.18181Z","shell.execute_reply.started":"2024-08-08T17:20:27.175512Z","shell.execute_reply":"2024-08-08T17:20:27.180451Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn  \nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom torch import nn\nimport torch.nn.functional as F\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.set_default_device(device)\n\ndf = pd.read_csv('https://raw.githubusercontent.com/HalyshAnton/IT-Step-Pyton-AI/main/module3/data/MultiJetRun2010B.csv')\ndf = df[df['nBJets'] != 2]\n\ncolumns = df.columns.delete(-1)\ndata = df[columns]\ndf[columns] = (data - data.min()) / (data.max() - data.min())","metadata":{"execution":{"iopub.status.busy":"2024-08-08T17:20:27.187433Z","iopub.execute_input":"2024-08-08T17:20:27.188314Z","iopub.status.idle":"2024-08-08T17:20:27.934542Z","shell.execute_reply.started":"2024-08-08T17:20:27.188272Z","shell.execute_reply":"2024-08-08T17:20:27.933494Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"class ProtonDecayDataset(Dataset):\n    def __init__(self, data, targets):\n        self.data = torch.FloatTensor(data.values)\n        self.targets = torch.FloatTensor(targets.values).reshape(-1, 1)\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        return self.data[index], self.targets[index]","metadata":{"execution":{"iopub.status.busy":"2024-08-08T17:20:27.936232Z","iopub.execute_input":"2024-08-08T17:20:27.936565Z","iopub.status.idle":"2024-08-08T17:20:27.942761Z","shell.execute_reply.started":"2024-08-08T17:20:27.936538Z","shell.execute_reply":"2024-08-08T17:20:27.941581Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"X = df.drop(columns=['nBJets'])\ny = df['nBJets']\n\nX_train, X_test, y_train, y_test, = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\ntrain_dataset = ProtonDecayDataset(X_train, y_train)\ntest_dataset = ProtonDecayDataset(X_test, y_test)\n\nbatch_size = 512\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T17:20:27.944077Z","iopub.execute_input":"2024-08-08T17:20:27.944438Z","iopub.status.idle":"2024-08-08T17:20:27.973992Z","shell.execute_reply.started":"2024-08-08T17:20:27.94441Z","shell.execute_reply":"2024-08-08T17:20:27.972791Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        \n        self.linear = nn.Linear(input_dim, output_dim)\n        self.linear1 = nn.Linear(output_dim, output_dim)\n        self.linear2 = nn.Linear(output_dim, output_dim)\n        \n        self.bn1 = nn.BatchNorm1d(output_dim)  \n        self.bn2 = nn.BatchNorm1d(output_dim)  \n        \n    def forward(self, x):\n        x = self.linear(x)\n        x = F.relu(x)\n        \n        out = self.linear1(x)\n        out = self.bn1(out)\n        out = F.relu(out)\n        \n        out = self.linear2(out)\n        out = self.bn2(out)\n        out = F.relu(out)\n        \n        return out + x\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T17:20:27.976362Z","iopub.execute_input":"2024-08-08T17:20:27.976846Z","iopub.status.idle":"2024-08-08T17:20:27.984823Z","shell.execute_reply.started":"2024-08-08T17:20:27.976807Z","shell.execute_reply":"2024-08-08T17:20:27.983763Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"class BinaryClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n\n        self.all_layers = nn.Sequential(\n          Block(input_dim, hidden_dim),\n          nn.Dropout(0.2),\n          Block(hidden_dim, hidden_dim//2),\n\n          nn.Linear(hidden_dim//2, hidden_dim//2),\n          nn.ReLU(),\n          nn.Linear(hidden_dim//2, output_dim),\n          nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.all_layers(x)\n\n\n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n\n        with torch.no_grad():\n          y_pred = self.forward(X)\n\n        return y_pred.cpu().numpy()\n\n\nmodel = BinaryClassifier(4, 128, 1).to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-08-08T17:20:27.986037Z","iopub.execute_input":"2024-08-08T17:20:27.986389Z","iopub.status.idle":"2024-08-08T17:20:28.011153Z","shell.execute_reply.started":"2024-08-08T17:20:27.98636Z","shell.execute_reply":"2024-08-08T17:20:28.010022Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"BinaryClassifier(\n  (all_layers): Sequential(\n    (0): Block(\n      (linear): Linear(in_features=4, out_features=128, bias=True)\n      (linear1): Linear(in_features=128, out_features=128, bias=True)\n      (linear2): Linear(in_features=128, out_features=128, bias=True)\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Dropout(p=0.2, inplace=False)\n    (2): Block(\n      (linear): Linear(in_features=128, out_features=64, bias=True)\n      (linear1): Linear(in_features=64, out_features=64, bias=True)\n      (linear2): Linear(in_features=64, out_features=64, bias=True)\n      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): Linear(in_features=64, out_features=64, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=64, out_features=1, bias=True)\n    (6): Sigmoid()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"from torchsummary import summary\n\nsummary(model, input_size=(4,))","metadata":{"execution":{"iopub.status.busy":"2024-08-08T17:22:11.588208Z","iopub.execute_input":"2024-08-08T17:22:11.588657Z","iopub.status.idle":"2024-08-08T17:22:11.621242Z","shell.execute_reply.started":"2024-08-08T17:22:11.588623Z","shell.execute_reply":"2024-08-08T17:22:11.619765Z"},"trusted":true},"execution_count":53,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[1;32m      3\u001b[0m summary(model, input_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m,))\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"],"ename":"ModuleNotFoundError","evalue":"No module named 'torchsummary'","output_type":"error"}]}]}