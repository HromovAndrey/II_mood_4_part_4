{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/andrey36912/notebook6ff449cabb?scriptVersionId=191679034\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-08T17:03:43.88116Z","iopub.execute_input":"2024-08-08T17:03:43.881562Z","iopub.status.idle":"2024-08-08T17:03:43.888286Z","shell.execute_reply.started":"2024-08-08T17:03:43.881515Z","shell.execute_reply":"2024-08-08T17:03:43.886983Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn  \nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom torch import nn\nimport torch.nn.functional as F\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.set_default_device(device)\n\ndf = pd.read_csv('https://raw.githubusercontent.com/HalyshAnton/IT-Step-Pyton-AI/main/module3/data/MultiJetRun2010B.csv')\ndf = df[df['nBJets'] != 2]\n\ncolumns = df.columns.delete(-1)\ndata = df[columns]\ndf[columns] = (data - data.min()) / (data.max() - data.min())","metadata":{"execution":{"iopub.status.busy":"2024-08-08T17:03:43.890756Z","iopub.execute_input":"2024-08-08T17:03:43.8913Z","iopub.status.idle":"2024-08-08T17:03:44.335746Z","shell.execute_reply.started":"2024-08-08T17:03:43.891245Z","shell.execute_reply":"2024-08-08T17:03:44.334624Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class ProtonDecayDataset(Dataset):\n    def __init__(self, data, targets):\n        self.data = torch.FloatTensor(data.values)\n        self.targets = torch.FloatTensor(targets.values).reshape(-1, 1)\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        return self.data[index], self.targets[index]","metadata":{"execution":{"iopub.status.busy":"2024-08-08T17:03:44.337618Z","iopub.execute_input":"2024-08-08T17:03:44.337954Z","iopub.status.idle":"2024-08-08T17:03:44.344338Z","shell.execute_reply.started":"2024-08-08T17:03:44.337925Z","shell.execute_reply":"2024-08-08T17:03:44.343182Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"X = df.drop(columns=['nBJets'])\ny = df['nBJets']\n\nX_train, X_test, y_train, y_test, = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\ntrain_dataset = ProtonDecayDataset(X_train, y_train)\ntest_dataset = ProtonDecayDataset(X_test, y_test)\n\nbatch_size = 512\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T17:03:44.345734Z","iopub.execute_input":"2024-08-08T17:03:44.346087Z","iopub.status.idle":"2024-08-08T17:03:44.375636Z","shell.execute_reply.started":"2024-08-08T17:03:44.34606Z","shell.execute_reply":"2024-08-08T17:03:44.374326Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        \n        self.linear = nn.Linear(input_dim, output_dim)\n        self.linear1 = nn.Linear(output_dim, output_dim)\n        self.linear2 = nn.Linear(output_dim, output_dim)\n        \n        self.dn1 = nn.BatchNorm1d(output_dim)\n        self.bn2 = nn.BatchNormld(output_dim)\n        \n        \n    def forward(self, x):\n        x = self.linear(x)\n        x = F.relu(x)\n        \n        out = self.linear1(x)\n        out = self.bn1(out)\n        out = F.relu(out)\n        \n        out = self.linear2(out)\n        out = self.bn2(out)\n        out = F.relu(out)\n        \n        return out + x","metadata":{"execution":{"iopub.status.busy":"2024-08-08T17:03:44.377736Z","iopub.execute_input":"2024-08-08T17:03:44.378082Z","iopub.status.idle":"2024-08-08T17:03:44.386751Z","shell.execute_reply.started":"2024-08-08T17:03:44.378042Z","shell.execute_reply":"2024-08-08T17:03:44.385354Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"class BinaryClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n\n        self.all_layers = nn.Sequential(\n          Block(input_dim, hidden_dim),\n          nn.Dropout(0.2),\n          Block(hidden_dim, hidden_dim//2),\n\n          nn.Linear(hidden_dim//2, hidden_dim//2),\n          nn.ReLU(),\n          nn.Linear(hidden_dim//2, output_dim),\n          nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.all_layers(x)\n\n\n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n\n        with torch.no_grad():\n          y_pred = self.forward(X)\n\n        return y_pred.cpu().numpy()\n\n\nmodel = BinaryClassifier(4, 128, 1).to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-08-08T17:03:44.388002Z","iopub.execute_input":"2024-08-08T17:03:44.388343Z","iopub.status.idle":"2024-08-08T17:03:44.499493Z","shell.execute_reply.started":"2024-08-08T17:03:44.388308Z","shell.execute_reply":"2024-08-08T17:03:44.497867Z"},"trusted":true},"execution_count":46,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[46], line 29\u001b[0m\n\u001b[1;32m     24\u001b[0m           y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 29\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBinaryClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m model\n","Cell \u001b[0;32mIn[46], line 6\u001b[0m, in \u001b[0;36mBinaryClassifier.__init__\u001b[0;34m(self, input_dim, hidden_dim, output_dim)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dim, hidden_dim, output_dim):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_layers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m----> 6\u001b[0m       \u001b[43mBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      7\u001b[0m       nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.2\u001b[39m),\n\u001b[1;32m      8\u001b[0m       Block(hidden_dim, hidden_dim\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m       nn\u001b[38;5;241m.\u001b[39mLinear(hidden_dim\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, hidden_dim\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     11\u001b[0m       nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m     12\u001b[0m       nn\u001b[38;5;241m.\u001b[39mLinear(hidden_dim\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, output_dim),\n\u001b[1;32m     13\u001b[0m       nn\u001b[38;5;241m.\u001b[39mSigmoid()\n\u001b[1;32m     14\u001b[0m     )\n","Cell \u001b[0;32mIn[45], line 10\u001b[0m, in \u001b[0;36mBlock.__init__\u001b[0;34m(self, input_dim, output_dim)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(output_dim, output_dim)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdn1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBatchNorm1d(output_dim)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2 \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchNormld\u001b[49m(output_dim)\n","\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'BatchNormld'"],"ename":"AttributeError","evalue":"module 'torch.nn' has no attribute 'BatchNormld'","output_type":"error"}]}]}