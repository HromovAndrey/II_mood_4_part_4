{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/andrey36912/notebook6ff449cabb?scriptVersionId=191757799\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-09T08:13:43.007539Z","iopub.execute_input":"2024-08-09T08:13:43.008028Z","iopub.status.idle":"2024-08-09T08:13:43.016177Z","shell.execute_reply.started":"2024-08-09T08:13:43.007993Z","shell.execute_reply":"2024-08-09T08:13:43.014935Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn  \nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nfrom torch import nn\nimport torch.nn.functional as F\n\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ntorch.set_default_device(device)\n\ndf = pd.read_csv('https://raw.githubusercontent.com/HalyshAnton/IT-Step-Pyton-AI/main/module3/data/MultiJetRun2010B.csv')\ndf = df[df['nBJets'] != 2]\n\ncolumns = df.columns.delete(-1)\ndata = df[columns]\ndf[columns] = (data - data.min()) / (data.max() - data.min())","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:13:43.027322Z","iopub.execute_input":"2024-08-09T08:13:43.027746Z","iopub.status.idle":"2024-08-09T08:13:43.776068Z","shell.execute_reply.started":"2024-08-09T08:13:43.027713Z","shell.execute_reply":"2024-08-09T08:13:43.774868Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"class ProtonDecayDataset(Dataset):\n    def __init__(self, data, targets):\n        self.data = torch.FloatTensor(data.values)\n        self.targets = torch.FloatTensor(targets.values).reshape(-1, 1)\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        return self.data[index], self.targets[index]","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:13:43.778275Z","iopub.execute_input":"2024-08-09T08:13:43.778711Z","iopub.status.idle":"2024-08-09T08:13:43.787207Z","shell.execute_reply.started":"2024-08-09T08:13:43.778672Z","shell.execute_reply":"2024-08-09T08:13:43.785946Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"X = df.drop(columns=['nBJets'])\ny = df['nBJets']\n\nX_train, X_test, y_train, y_test, = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\ntrain_dataset = ProtonDecayDataset(X_train, y_train)\ntest_dataset = ProtonDecayDataset(X_test, y_test)\n\nbatch_size = 512\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:13:43.790827Z","iopub.execute_input":"2024-08-09T08:13:43.791204Z","iopub.status.idle":"2024-08-09T08:13:43.818789Z","shell.execute_reply.started":"2024-08-09T08:13:43.791174Z","shell.execute_reply":"2024-08-09T08:13:43.817692Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"class Block(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        \n        self.linear = nn.Linear(input_dim, output_dim)\n        self.linear1 = nn.Linear(output_dim, output_dim)\n        self.linear2 = nn.Linear(output_dim, output_dim)\n        \n        self.bn1 = nn.BatchNorm1d(output_dim)  \n        self.bn2 = nn.BatchNorm1d(output_dim)  \n        \n    def forward(self, x):\n        x = self.linear(x)\n        x = F.relu(x)\n        \n        out = self.linear1(x)\n        out = self.bn1(out)\n        out = F.relu(out)\n        \n        out = self.linear2(out)\n        out = self.bn2(out)\n        out = F.relu(out)\n        \n        return out + x\n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:13:43.821951Z","iopub.execute_input":"2024-08-09T08:13:43.822586Z","iopub.status.idle":"2024-08-09T08:13:43.83119Z","shell.execute_reply.started":"2024-08-09T08:13:43.822543Z","shell.execute_reply":"2024-08-09T08:13:43.830184Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"class BinaryClassifier(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super().__init__()\n\n        self.all_layers = nn.Sequential(\n          Block(input_dim, hidden_dim),\n          nn.Dropout(0.2),\n          Block(hidden_dim, hidden_dim//2),\n\n          nn.Linear(hidden_dim//2, hidden_dim//2),\n          nn.ReLU(),\n          nn.Linear(hidden_dim//2, output_dim),\n          nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        return self.all_layers(x)\n\n\n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n\n        with torch.no_grad():\n            y_pred = self.forward(X)\n\n        return y_pred.cpu().numpy()\n\n\nmodel = BinaryClassifier(4, 128, 1).to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:13:43.83252Z","iopub.execute_input":"2024-08-09T08:13:43.832942Z","iopub.status.idle":"2024-08-09T08:13:43.855449Z","shell.execute_reply.started":"2024-08-09T08:13:43.832898Z","shell.execute_reply":"2024-08-09T08:13:43.854333Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"BinaryClassifier(\n  (all_layers): Sequential(\n    (0): Block(\n      (linear): Linear(in_features=4, out_features=128, bias=True)\n      (linear1): Linear(in_features=128, out_features=128, bias=True)\n      (linear2): Linear(in_features=128, out_features=128, bias=True)\n      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): Dropout(p=0.2, inplace=False)\n    (2): Block(\n      (linear): Linear(in_features=128, out_features=64, bias=True)\n      (linear1): Linear(in_features=64, out_features=64, bias=True)\n      (linear2): Linear(in_features=64, out_features=64, bias=True)\n      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): Linear(in_features=64, out_features=64, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=64, out_features=1, bias=True)\n    (6): Sigmoid()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"pip install torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:13:43.856821Z","iopub.execute_input":"2024-08-09T08:13:43.857225Z","iopub.status.idle":"2024-08-09T08:13:58.028901Z","shell.execute_reply.started":"2024-08-09T08:13:43.857195Z","shell.execute_reply":"2024-08-09T08:13:58.027397Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchsummary import summary\n\nsummary(model, input_size=(4,))","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:13:58.030975Z","iopub.execute_input":"2024-08-09T08:13:58.031365Z","iopub.status.idle":"2024-08-09T08:13:58.047506Z","shell.execute_reply.started":"2024-08-09T08:13:58.031331Z","shell.execute_reply":"2024-08-09T08:13:58.045472Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Linear-1                  [-1, 128]             640\n            Linear-2                  [-1, 128]          16,512\n       BatchNorm1d-3                  [-1, 128]             256\n            Linear-4                  [-1, 128]          16,512\n       BatchNorm1d-5                  [-1, 128]             256\n             Block-6                  [-1, 128]               0\n           Dropout-7                  [-1, 128]               0\n            Linear-8                   [-1, 64]           8,256\n            Linear-9                   [-1, 64]           4,160\n      BatchNorm1d-10                   [-1, 64]             128\n           Linear-11                   [-1, 64]           4,160\n      BatchNorm1d-12                   [-1, 64]             128\n            Block-13                   [-1, 64]               0\n           Linear-14                   [-1, 64]           4,160\n             ReLU-15                   [-1, 64]               0\n           Linear-16                    [-1, 1]              65\n          Sigmoid-17                    [-1, 1]               0\n================================================================\nTotal params: 55,233\nTrainable params: 55,233\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.01\nParams size (MB): 0.21\nEstimated Total Size (MB): 0.22\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"loss_fn = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-6)\nfrom torch.optim.lr_scheduler import StepLR\nscheduler = StepLR(optimizer, step_size=5, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:13:58.048869Z","iopub.execute_input":"2024-08-09T08:13:58.050627Z","iopub.status.idle":"2024-08-09T08:13:58.059512Z","shell.execute_reply.started":"2024-08-09T08:13:58.050596Z","shell.execute_reply":"2024-08-09T08:13:58.058353Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR\n\nscheduler = StepLR(optimizer, step_size=5, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:13:58.061172Z","iopub.execute_input":"2024-08-09T08:13:58.061631Z","iopub.status.idle":"2024-08-09T08:13:58.073543Z","shell.execute_reply.started":"2024-08-09T08:13:58.061594Z","shell.execute_reply":"2024-08-09T08:13:58.072456Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"import time\n\ndef train(model, optimizer, loss_fn, train_dl, val_dl,\n         metrics=None, metrics_name=None, epochs=20, device='cpu', task='regression'):\n    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n         (type(model).__name__, type(optimizer).__name__,\n         optimizer.param_groups[0]['lr'], epochs, device))\n    \n    metrics = mrtrics if metrics else []\n    metrics_name = metrics_name if metrics_name else [metric.__name__ for metric in metrics]\n    history = {}\n    history['lr'] = []\n    history['val_loss'] = []\n    for name in metrics_name:\n        history[naem] = []\n        history[f'val_{name}'] = []\n        \n    start_time_train = time.time()\n    \n    for epoch in reange(epochs):\n        \n        start_time_epoch = time.time()\n        model.train()\n        history_train = {name: 0 for name in ['loss']+metrics_name}\n        for batch in train_dl:\n            x = batch[0].to(device)\n            y = batch[1].to(device)\n            y_pred = model(x)\n            loss = loss_fn(y_pred, y)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            y_pred = y_pred.detach() cpu ().numpy()\n            y = y.detach().cpu().numpy()\n            \n            history_train['loss'] += loss.item() * x.size(0)\n            for name, func in zip(metrics_name, metrics):\n                try:\n                    history_train[name] += func(y, y_pred) * x.size(0)\n                except:\n                    if task == 'binary': y_pred_= y_pred.round()\n                    elif task == 'multiclass' : y_pred_ = y_pred.argmax(axis=-1)\n                    history_train[name] += func(y, y_pred_) * x.size(0)\n            for name in history_val:\n                history_val[name] /= len(val_dl.dataset)\n                \n            end_time_epoch = time.time()\n                \n            for name history_train:\n                history[name].append(history_train[name])\n                history['val_'+name].append(history_val['val_'+name])\n                    \n            total_time_epoch = end_time_epoch - start_time_epoch\n                \n            print(f'Epoch {epoch+1:4d} {total_time_epoch:4.0f}sec', end='\\t')\n            for name in history_train:\n                print(f'{name}: {history[name][-1]:10.3g}', end='\\t')\n                print(f\"val_{name}: {history['val_'+name][-1]:10.3g}\", end='\\t')\n            print()\n                \nend_time_train = time.time()\ntotal_time_train = end_time_train - start_time_train\nprint()\nprint('Time total: %5.2f sec' % (total_time_treain))\nreturn history\n            \n","metadata":{"execution":{"iopub.status.busy":"2024-08-09T08:15:57.914786Z","iopub.execute_input":"2024-08-09T08:15:57.915206Z","iopub.status.idle":"2024-08-09T08:15:57.935446Z","shell.execute_reply.started":"2024-08-09T08:15:57.915174Z","shell.execute_reply":"2024-08-09T08:15:57.933761Z"},"trusted":true},"execution_count":49,"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[49], line 35\u001b[0;36m\u001b[0m\n\u001b[0;31m    y_pred = y_pred.detach() cpu ().numpy()\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (3551448902.py, line 35)","output_type":"error"}]}]}